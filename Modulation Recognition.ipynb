{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset Button. Press when memory goes crazy fat !\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports cell\n",
    "import numpy as np\n",
    "import _pickle as cPickle\n",
    "import sys \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Deep Learning libs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start with data\n",
    "\n",
    "We use DeepSig Dataset: RadioML 2016.04C<br>\n",
    "A synthetic dataset, generated with GNU Radio, consisting of 11 modulations. This is a\n",
    "variable-SNR dataset with moderate LO drift, light fading, and numerous different\n",
    "labeled SNR increments for use in measuring performance across different signal and\n",
    "noise power scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "**The file is formatted as a \"pickle\" file which can be open for example in python by using cPickle.load(...)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"RML2016.10b.dat\"\n",
    "open_file = open(filename,'rb')\n",
    "data = cPickle.load(open_file, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use lists when accessing data from dict for ease of access.\n",
    "keys_list = list(data.keys())\n",
    "temp_list = []\n",
    "label_list = []\n",
    "snr_list = []\n",
    "for i in range(len(keys_list)):\n",
    "    curr_item = data[keys_list[i]] \n",
    "    temp_list.append(curr_item)\n",
    "    for j in range(curr_item.shape[0]):\n",
    "        label_list.append(keys_list[i][0])\n",
    "    #for j in rane(curr_item.shape[0]):\n",
    "    #    snr_list.append(keys_list[i][1])\n",
    "\n",
    "# Convert all lists into numpy arrays.\n",
    "X = np.array(temp_list).reshape(1200000,2,128)\n",
    "Y = np.array(label_list)\n",
    "\n",
    "# Clear All un-neccsarry lists created.\n",
    "temp_list.clear()\n",
    "label_list.clear()\n",
    "snr_list.clear()\n",
    "keys_list.clear()\n",
    "data.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feature Spaces for data\n",
    "\n",
    "**Every sample is presented using two vectors each of them has 128 elements. Those two vectors are the in-phase and quadrature phase components of a sample.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivative_X = np.arange(1200000*4*128, dtype=\"float32\").reshape(1200000,4,128)\n",
    "derivative_X = np.concatenate((np.apply_along_axis(lambda column:np.gradient(column),2,X),X),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_X = np.arange(1200000*4*128, dtype=\"float32\").reshape(1200000,4,128)\n",
    "integral_X =np.concatenate((np.apply_along_axis(lambda column:np.hstack((0,column)),2,np.apply_along_axis(lambda column:sp.integrate.cumtrapz(column,dx=1,axis=-1),2,X)),X),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data\n",
    "\n",
    "**Split the data into 50% for training/validation and 50% for testing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(X,Y, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Labels\n",
    "\n",
    "Our class labels are currently represented as strings; however, Keras will assume that both:\n",
    "\n",
    "1. Labels are encoded as integers\n",
    "\n",
    "2. And furthermore, one-hot encoding is performed on these labels making each label represented as a vector rather than an integer\n",
    "\n",
    "To accomplish this encoding, we can use the LabelBinarizer  class from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Fully Connected Model\n",
    "<ul>\n",
    "\n",
    "1. The core data structure of Keras is a model. The simplest type of model is the Sequential model, a linear stack of layers.\n",
    "\n",
    "2. A 3-layer deep neural network consisiting only of fully connected layers of size 512, 256, 11 neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 2, 512)            66048     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 2, 256)            131328    \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 202,506\n",
      "Trainable params: 202,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Declare layers size\n",
    "in_shape = (2,128)\n",
    "hidden1_size = 512\n",
    "hidden2_size = 256\n",
    "hidden3_size = 10\n",
    "\n",
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden1_size, input_shape = in_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(hidden2_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden3_size))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model\n",
    "\n",
    "1. The training process will run for a fixed number of iterations (epochs) through the dataset.\n",
    "\n",
    "2. We can also set the number of instances that are evaluated before a weight update in the network is performed (batch size).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "600000/600000 [==============================] - 16s 27us/step - loss: 8.7334 - acc: 0.1752\n",
      "Epoch 2/150\n",
      "600000/600000 [==============================] - 15s 25us/step - loss: 8.7333 - acc: 0.1753\n",
      "Epoch 3/150\n",
      "600000/600000 [==============================] - 16s 26us/step - loss: 8.7332 - acc: 0.1755\n",
      "Epoch 4/150\n",
      "600000/600000 [==============================] - 15s 25us/step - loss: 8.7332 - acc: 0.1757\n",
      "Epoch 5/150\n",
      "600000/600000 [==============================] - 16s 26us/step - loss: 8.7333 - acc: 0.1759\n",
      "Epoch 6/150\n",
      "600000/600000 [==============================] - 15s 25us/step - loss: 8.7333 - acc: 0.1759\n",
      "Epoch 7/150\n",
      "600000/600000 [==============================] - 15s 25us/step - loss: 8.7333 - acc: 0.1759\n",
      "Epoch 8/150\n",
      "300000/600000 [==============>...............] - ETA: 7s - loss: 8.7391 - acc: 0.1755"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=150, batch_size=300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([[1,2,3],[4,5,6]])\n",
    "azeros = np.zeros((2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack((0,a1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
