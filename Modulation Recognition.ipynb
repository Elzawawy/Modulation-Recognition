{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "#Reset Button. Press when memory goes crazy fat !\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports cell\n",
    "import numpy as np\n",
    "import _pickle as cPickle\n",
    "import sys \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Deep Learning libs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten,Conv2D,ZeroPadding2D\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start with data\n",
    "\n",
    "We use DeepSig Dataset: RadioML 2016.04C<br>\n",
    "A synthetic dataset, generated with GNU Radio, consisting of 11 modulations. This is a\n",
    "variable-SNR dataset with moderate LO drift, light fading, and numerous different\n",
    "labeled SNR increments for use in measuring performance across different signal and\n",
    "noise power scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "**The file is formatted as a \"pickle\" file which can be open for example in python by using cPickle.load(...)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"RML2016.10b.dat\"\n",
    "open_file = open(filename,'rb')\n",
    "data = cPickle.load(open_file, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use lists when accessing data from dict for ease of access.\n",
    "keys_list = list(data.keys())\n",
    "temp_list = []\n",
    "label_list = []\n",
    "snr_list = []\n",
    "for i in range(len(keys_list)):\n",
    "    curr_item = data[keys_list[i]] \n",
    "    temp_list.append(curr_item)\n",
    "    for j in range(curr_item.shape[0]):\n",
    "        label_list.append(keys_list[i][0])\n",
    "    #for j in rane(curr_item.shape[0]):\n",
    "    #    snr_list.append(keys_list[i][1])\n",
    "\n",
    "# Convert all lists into numpy arrays.\n",
    "X = np.array(temp_list).reshape(1200000,2,128)\n",
    "Y = np.array(label_list)\n",
    "\n",
    "# Clear All un-neccsarry lists created.\n",
    "temp_list.clear()\n",
    "label_list.clear()\n",
    "snr_list.clear()\n",
    "keys_list.clear()\n",
    "data.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feature Spaces for data\n",
    "\n",
    "**Every sample is presented using two vectors each of them has 128 elements. Those two vectors are the in-phase and quadrature phase components of a sample.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivative_X = np.arange(1200000*4*128, dtype=\"float32\").reshape(1200000,4,128)\n",
    "derivative_X = np.concatenate((np.apply_along_axis(lambda column:np.gradient(column),2,X),X),axis=1)\n",
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_X = np.arange(1200000*4*128, dtype=\"float32\").reshape(1200000,4,128)\n",
    "integral_X =np.concatenate((np.apply_along_axis(lambda column:np.hstack((0,column)),2,np.apply_along_axis(lambda column:sp.integrate.cumtrapz(column,dx=1,axis=-1),2,X)),X),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data\n",
    "\n",
    "**Split the data into 50% for training/validation and 50% for testing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(trainX, testX, trainY, testY) = train_test_split(X,Y, test_size=0.50, random_state=42)\n",
    "(trainX, testX, trainY, testY) = train_test_split(derivative_X,Y, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del derivative_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Labels\n",
    "\n",
    "Our class labels are currently represented as strings; however, Keras will assume that both:\n",
    "\n",
    "1. Labels are encoded as integers\n",
    "\n",
    "2. And furthermore, one-hot encoding is performed on these labels making each label represented as a vector rather than an integer\n",
    "\n",
    "To accomplish this encoding, we can use the LabelBinarizer  class from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Fully Connected Model\n",
    "<ul>\n",
    "\n",
    "1. The core data structure of Keras is a model. The simplest type of model is the Sequential model, a linear stack of layers.\n",
    "\n",
    "2. A 3-layer deep neural network consisiting only of fully connected layers of size 512, 256, 11 neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zawawy/Public/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4, 512)            66048     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 512)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4, 256)            131328    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 207,626\n",
      "Trainable params: 207,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Declare layers size\n",
    "in_shape = (4,128)\n",
    "hidden1_size = 512\n",
    "hidden2_size = 256\n",
    "hidden3_size = 10\n",
    "\n",
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden1_size, input_shape = in_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(hidden2_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden3_size))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model\n",
    "\n",
    "1. The training process will run for a fixed number of iterations (epochs) through the dataset.\n",
    "\n",
    "2. We can also set the number of instances that are evaluated before a weight update in the network is performed (batch size).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zawawy/Public/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 570000 samples, validate on 30000 samples\n",
      "Epoch 1/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 2.3007 - acc: 0.1443 - val_loss: 2.2971 - val_acc: 0.1626\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.16263, saving model to best_model_2.h5\n",
      "Epoch 2/150\n",
      "570000/570000 [==============================] - 34s 60us/step - loss: 2.2929 - acc: 0.1637 - val_loss: 2.2828 - val_acc: 0.1697\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.16263 to 0.16970, saving model to best_model_2.h5\n",
      "Epoch 3/150\n",
      "570000/570000 [==============================] - 35s 61us/step - loss: 2.2727 - acc: 0.1668 - val_loss: 2.2492 - val_acc: 0.1707\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.16970 to 0.17070, saving model to best_model_2.h5\n",
      "Epoch 4/150\n",
      "570000/570000 [==============================] - 33s 59us/step - loss: 2.2309 - acc: 0.1721 - val_loss: 2.1917 - val_acc: 0.1794\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.17070 to 0.17937, saving model to best_model_2.h5\n",
      "Epoch 5/150\n",
      "570000/570000 [==============================] - 30s 53us/step - loss: 2.1722 - acc: 0.1768 - val_loss: 2.1352 - val_acc: 0.1762\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.17937\n",
      "Epoch 6/150\n",
      "570000/570000 [==============================] - 33s 57us/step - loss: 2.1317 - acc: 0.1803 - val_loss: 2.1153 - val_acc: 0.1866\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.17937 to 0.18663, saving model to best_model_2.h5\n",
      "Epoch 7/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 2.1171 - acc: 0.1901 - val_loss: 2.1002 - val_acc: 0.2011\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.18663 to 0.20113, saving model to best_model_2.h5\n",
      "Epoch 8/150\n",
      "570000/570000 [==============================] - 34s 59us/step - loss: 2.1005 - acc: 0.1970 - val_loss: 2.0845 - val_acc: 0.1912\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.20113\n",
      "Epoch 9/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 2.0851 - acc: 0.2000 - val_loss: 2.0716 - val_acc: 0.1956\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.20113\n",
      "Epoch 10/150\n",
      "570000/570000 [==============================] - 32s 57us/step - loss: 2.0712 - acc: 0.2038 - val_loss: 2.0571 - val_acc: 0.2056\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.20113 to 0.20563, saving model to best_model_2.h5\n",
      "Epoch 11/150\n",
      "570000/570000 [==============================] - 34s 59us/step - loss: 2.0575 - acc: 0.2063 - val_loss: 2.0442 - val_acc: 0.2101\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.20563 to 0.21007, saving model to best_model_2.h5\n",
      "Epoch 12/150\n",
      "570000/570000 [==============================] - 34s 59us/step - loss: 2.0442 - acc: 0.2107 - val_loss: 2.0303 - val_acc: 0.2126\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.21007 to 0.21263, saving model to best_model_2.h5\n",
      "Epoch 13/150\n",
      "570000/570000 [==============================] - 33s 59us/step - loss: 2.0293 - acc: 0.2167 - val_loss: 2.0147 - val_acc: 0.2231\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.21263 to 0.22307, saving model to best_model_2.h5\n",
      "Epoch 14/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 2.0127 - acc: 0.2254 - val_loss: 1.9968 - val_acc: 0.2282\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.22307 to 0.22823, saving model to best_model_2.h5\n",
      "Epoch 15/150\n",
      "570000/570000 [==============================] - 34s 59us/step - loss: 1.9937 - acc: 0.2338 - val_loss: 1.9764 - val_acc: 0.2368\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.22823 to 0.23677, saving model to best_model_2.h5\n",
      "Epoch 16/150\n",
      "570000/570000 [==============================] - 31s 54us/step - loss: 1.9732 - acc: 0.2433 - val_loss: 1.9555 - val_acc: 0.2489\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.23677 to 0.24890, saving model to best_model_2.h5\n",
      "Epoch 17/150\n",
      "570000/570000 [==============================] - 31s 54us/step - loss: 1.9494 - acc: 0.2522 - val_loss: 1.9315 - val_acc: 0.2558\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.24890 to 0.25577, saving model to best_model_2.h5\n",
      "Epoch 18/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.9245 - acc: 0.2627 - val_loss: 1.9070 - val_acc: 0.2680\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.25577 to 0.26803, saving model to best_model_2.h5\n",
      "Epoch 19/150\n",
      "570000/570000 [==============================] - 31s 54us/step - loss: 1.8993 - acc: 0.2708 - val_loss: 1.8820 - val_acc: 0.2741\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.26803 to 0.27413, saving model to best_model_2.h5\n",
      "Epoch 20/150\n",
      "570000/570000 [==============================] - 34s 60us/step - loss: 1.8749 - acc: 0.2777 - val_loss: 1.8605 - val_acc: 0.2821\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.27413 to 0.28210, saving model to best_model_2.h5\n",
      "Epoch 21/150\n",
      "570000/570000 [==============================] - 33s 57us/step - loss: 1.8529 - acc: 0.2833 - val_loss: 1.8419 - val_acc: 0.2892\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.28210 to 0.28920, saving model to best_model_2.h5\n",
      "Epoch 22/150\n",
      "570000/570000 [==============================] - 31s 55us/step - loss: 1.8330 - acc: 0.2901 - val_loss: 1.8208 - val_acc: 0.2935\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.28920 to 0.29350, saving model to best_model_2.h5\n",
      "Epoch 23/150\n",
      "570000/570000 [==============================] - 32s 56us/step - loss: 1.8151 - acc: 0.2949 - val_loss: 1.8048 - val_acc: 0.2923\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.29350\n",
      "Epoch 24/150\n",
      "570000/570000 [==============================] - 33s 59us/step - loss: 1.8002 - acc: 0.2997 - val_loss: 1.7922 - val_acc: 0.2981\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.29350 to 0.29807, saving model to best_model_2.h5\n",
      "Epoch 25/150\n",
      "570000/570000 [==============================] - 36s 62us/step - loss: 1.7876 - acc: 0.3036 - val_loss: 1.7808 - val_acc: 0.3011\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.29807 to 0.30107, saving model to best_model_2.h5\n",
      "Epoch 26/150\n",
      "570000/570000 [==============================] - 35s 61us/step - loss: 1.7764 - acc: 0.3066 - val_loss: 1.7709 - val_acc: 0.3085\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.30107 to 0.30850, saving model to best_model_2.h5\n",
      "Epoch 27/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.7663 - acc: 0.3110 - val_loss: 1.7616 - val_acc: 0.3131\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.30850 to 0.31313, saving model to best_model_2.h5\n",
      "Epoch 28/150\n",
      "570000/570000 [==============================] - 30s 53us/step - loss: 1.7575 - acc: 0.3136 - val_loss: 1.7560 - val_acc: 0.3165\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.31313 to 0.31653, saving model to best_model_2.h5\n",
      "Epoch 29/150\n",
      "570000/570000 [==============================] - 31s 54us/step - loss: 1.7503 - acc: 0.3166 - val_loss: 1.7474 - val_acc: 0.3175\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.31653 to 0.31750, saving model to best_model_2.h5\n",
      "Epoch 30/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 1.7431 - acc: 0.3195 - val_loss: 1.7410 - val_acc: 0.3179\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.31750 to 0.31790, saving model to best_model_2.h5\n",
      "Epoch 31/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.7370 - acc: 0.3208 - val_loss: 1.7363 - val_acc: 0.3213\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.31790 to 0.32130, saving model to best_model_2.h5\n",
      "Epoch 32/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 1.7311 - acc: 0.3237 - val_loss: 1.7326 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.32130 to 0.32237, saving model to best_model_2.h5\n",
      "Epoch 33/150\n",
      "570000/570000 [==============================] - 34s 59us/step - loss: 1.7274 - acc: 0.3250 - val_loss: 1.7257 - val_acc: 0.3222\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.32237\n",
      "Epoch 34/150\n",
      "570000/570000 [==============================] - 31s 54us/step - loss: 1.7217 - acc: 0.3279 - val_loss: 1.7235 - val_acc: 0.3210\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.32237\n",
      "Epoch 35/150\n",
      "570000/570000 [==============================] - 34s 60us/step - loss: 1.7184 - acc: 0.3287 - val_loss: 1.7179 - val_acc: 0.3249\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.32237 to 0.32487, saving model to best_model_2.h5\n",
      "Epoch 36/150\n",
      "570000/570000 [==============================] - 32s 56us/step - loss: 1.7139 - acc: 0.3310 - val_loss: 1.7137 - val_acc: 0.3289\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.32487 to 0.32887, saving model to best_model_2.h5\n",
      "Epoch 37/150\n",
      "570000/570000 [==============================] - 32s 57us/step - loss: 1.7096 - acc: 0.3331 - val_loss: 1.7112 - val_acc: 0.3324\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.32887 to 0.33240, saving model to best_model_2.h5\n",
      "Epoch 38/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 1.7060 - acc: 0.3350 - val_loss: 1.7090 - val_acc: 0.3342\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.33240 to 0.33420, saving model to best_model_2.h5\n",
      "Epoch 39/150\n",
      "570000/570000 [==============================] - 35s 62us/step - loss: 1.7034 - acc: 0.3359 - val_loss: 1.7056 - val_acc: 0.3354\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.33420 to 0.33540, saving model to best_model_2.h5\n",
      "Epoch 40/150\n",
      "570000/570000 [==============================] - 34s 59us/step - loss: 1.6997 - acc: 0.3381 - val_loss: 1.7017 - val_acc: 0.3350\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.33540\n",
      "Epoch 41/150\n",
      "570000/570000 [==============================] - 34s 60us/step - loss: 1.6963 - acc: 0.3395 - val_loss: 1.6988 - val_acc: 0.3339\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.33540\n",
      "Epoch 42/150\n",
      "570000/570000 [==============================] - 31s 54us/step - loss: 1.6934 - acc: 0.3411 - val_loss: 1.6962 - val_acc: 0.3373\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.33540 to 0.33730, saving model to best_model_2.h5\n",
      "Epoch 43/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 1.6904 - acc: 0.3421 - val_loss: 1.6934 - val_acc: 0.3418\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.33730 to 0.34180, saving model to best_model_2.h5\n",
      "Epoch 44/150\n",
      "570000/570000 [==============================] - 33s 57us/step - loss: 1.6876 - acc: 0.3442 - val_loss: 1.6905 - val_acc: 0.3409\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.34180\n",
      "Epoch 45/150\n",
      "570000/570000 [==============================] - 35s 61us/step - loss: 1.6851 - acc: 0.3454 - val_loss: 1.6886 - val_acc: 0.3429\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.34180 to 0.34293, saving model to best_model_2.h5\n",
      "Epoch 46/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.6823 - acc: 0.3463 - val_loss: 1.6852 - val_acc: 0.3435\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.34293 to 0.34353, saving model to best_model_2.h5\n",
      "Epoch 47/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.6792 - acc: 0.3477 - val_loss: 1.6825 - val_acc: 0.3448\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.34353 to 0.34477, saving model to best_model_2.h5\n",
      "Epoch 48/150\n",
      "570000/570000 [==============================] - 31s 54us/step - loss: 1.6764 - acc: 0.3488 - val_loss: 1.6802 - val_acc: 0.3462\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.34477 to 0.34623, saving model to best_model_2.h5\n",
      "Epoch 49/150\n",
      "570000/570000 [==============================] - 32s 57us/step - loss: 1.6738 - acc: 0.3506 - val_loss: 1.6780 - val_acc: 0.3504\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.34623 to 0.35043, saving model to best_model_2.h5\n",
      "Epoch 50/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.6707 - acc: 0.3522 - val_loss: 1.6742 - val_acc: 0.3497\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.35043\n",
      "Epoch 51/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.6678 - acc: 0.3531 - val_loss: 1.6715 - val_acc: 0.3486\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.35043\n",
      "Epoch 52/150\n",
      "570000/570000 [==============================] - 31s 54us/step - loss: 1.6652 - acc: 0.3538 - val_loss: 1.6700 - val_acc: 0.3533\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.35043 to 0.35333, saving model to best_model_2.h5\n",
      "Epoch 53/150\n",
      "570000/570000 [==============================] - 34s 60us/step - loss: 1.6624 - acc: 0.3564 - val_loss: 1.6684 - val_acc: 0.3494\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.35333\n",
      "Epoch 54/150\n",
      "570000/570000 [==============================] - 33s 59us/step - loss: 1.6606 - acc: 0.3563 - val_loss: 1.6657 - val_acc: 0.3551\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.35333 to 0.35513, saving model to best_model_2.h5\n",
      "Epoch 55/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.6564 - acc: 0.3586 - val_loss: 1.6599 - val_acc: 0.3543\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.35513\n",
      "Epoch 56/150\n",
      "570000/570000 [==============================] - 34s 61us/step - loss: 1.6527 - acc: 0.3593 - val_loss: 1.6573 - val_acc: 0.3557\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.35513 to 0.35573, saving model to best_model_2.h5\n",
      "Epoch 57/150\n",
      "570000/570000 [==============================] - 35s 61us/step - loss: 1.6493 - acc: 0.3612 - val_loss: 1.6541 - val_acc: 0.3558\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.35573 to 0.35580, saving model to best_model_2.h5\n",
      "Epoch 58/150\n",
      "570000/570000 [==============================] - 34s 60us/step - loss: 1.6461 - acc: 0.3619 - val_loss: 1.6511 - val_acc: 0.3581\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.35580 to 0.35813, saving model to best_model_2.h5\n",
      "Epoch 59/150\n",
      "570000/570000 [==============================] - 32s 56us/step - loss: 1.6432 - acc: 0.3619 - val_loss: 1.6500 - val_acc: 0.3588\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.35813 to 0.35883, saving model to best_model_2.h5\n",
      "Epoch 60/150\n",
      "570000/570000 [==============================] - 30s 53us/step - loss: 1.6401 - acc: 0.3627 - val_loss: 1.6441 - val_acc: 0.3610\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.35883 to 0.36097, saving model to best_model_2.h5\n",
      "Epoch 61/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.6352 - acc: 0.3643 - val_loss: 1.6393 - val_acc: 0.3620\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.36097 to 0.36200, saving model to best_model_2.h5\n",
      "Epoch 62/150\n",
      "570000/570000 [==============================] - 35s 62us/step - loss: 1.6311 - acc: 0.3653 - val_loss: 1.6363 - val_acc: 0.3649\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.36200 to 0.36487, saving model to best_model_2.h5\n",
      "Epoch 63/150\n",
      "570000/570000 [==============================] - 31s 55us/step - loss: 1.6273 - acc: 0.3658 - val_loss: 1.6330 - val_acc: 0.3658\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.36487 to 0.36577, saving model to best_model_2.h5\n",
      "Epoch 64/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.6240 - acc: 0.3660 - val_loss: 1.6304 - val_acc: 0.3610\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.36577\n",
      "Epoch 65/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 1.6209 - acc: 0.3666 - val_loss: 1.6277 - val_acc: 0.3632\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.36577\n",
      "Epoch 66/150\n",
      "570000/570000 [==============================] - 30s 53us/step - loss: 1.6174 - acc: 0.3675 - val_loss: 1.6213 - val_acc: 0.3665\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.36577 to 0.36653, saving model to best_model_2.h5\n",
      "Epoch 67/150\n",
      "570000/570000 [==============================] - 31s 55us/step - loss: 1.6144 - acc: 0.3677 - val_loss: 1.6241 - val_acc: 0.3623\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.36653\n",
      "Epoch 68/150\n",
      "570000/570000 [==============================] - 34s 59us/step - loss: 1.6117 - acc: 0.3684 - val_loss: 1.6155 - val_acc: 0.3667\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.36653 to 0.36673, saving model to best_model_2.h5\n",
      "Epoch 69/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 1.6084 - acc: 0.3694 - val_loss: 1.6113 - val_acc: 0.3705\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.36673 to 0.37047, saving model to best_model_2.h5\n",
      "Epoch 70/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 1.6046 - acc: 0.3708 - val_loss: 1.6084 - val_acc: 0.3711\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.37047 to 0.37110, saving model to best_model_2.h5\n",
      "Epoch 71/150\n",
      "570000/570000 [==============================] - 31s 54us/step - loss: 1.6011 - acc: 0.3718 - val_loss: 1.6044 - val_acc: 0.3726\n",
      "\n",
      "Epoch 00071: val_acc improved from 0.37110 to 0.37263, saving model to best_model_2.h5\n",
      "Epoch 72/150\n",
      "570000/570000 [==============================] - 32s 56us/step - loss: 1.5978 - acc: 0.3726 - val_loss: 1.6012 - val_acc: 0.3729\n",
      "\n",
      "Epoch 00072: val_acc improved from 0.37263 to 0.37287, saving model to best_model_2.h5\n",
      "Epoch 73/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570000/570000 [==============================] - 31s 55us/step - loss: 1.5932 - acc: 0.3745 - val_loss: 1.5979 - val_acc: 0.3735\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.37287 to 0.37350, saving model to best_model_2.h5\n",
      "Epoch 74/150\n",
      "570000/570000 [==============================] - 32s 57us/step - loss: 1.5893 - acc: 0.3760 - val_loss: 1.5949 - val_acc: 0.3743\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.37350 to 0.37427, saving model to best_model_2.h5\n",
      "Epoch 75/150\n",
      "570000/570000 [==============================] - 31s 54us/step - loss: 1.5860 - acc: 0.3769 - val_loss: 1.5922 - val_acc: 0.3721\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.37427\n",
      "Epoch 76/150\n",
      "570000/570000 [==============================] - 30s 53us/step - loss: 1.5833 - acc: 0.3761 - val_loss: 1.5901 - val_acc: 0.3753\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.37427 to 0.37527, saving model to best_model_2.h5\n",
      "Epoch 77/150\n",
      "570000/570000 [==============================] - 34s 60us/step - loss: 1.5802 - acc: 0.3784 - val_loss: 1.5868 - val_acc: 0.3774\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.37527 to 0.37743, saving model to best_model_2.h5\n",
      "Epoch 78/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 1.5774 - acc: 0.3785 - val_loss: 1.5844 - val_acc: 0.3761\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.37743\n",
      "Epoch 79/150\n",
      "570000/570000 [==============================] - 35s 61us/step - loss: 1.5745 - acc: 0.3788 - val_loss: 1.5809 - val_acc: 0.3774\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.37743\n",
      "Epoch 80/150\n",
      "570000/570000 [==============================] - 35s 62us/step - loss: 1.5715 - acc: 0.3798 - val_loss: 1.5785 - val_acc: 0.3766\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.37743\n",
      "Epoch 81/150\n",
      "570000/570000 [==============================] - 31s 55us/step - loss: 1.5691 - acc: 0.3795 - val_loss: 1.5757 - val_acc: 0.3785\n",
      "\n",
      "Epoch 00081: val_acc improved from 0.37743 to 0.37853, saving model to best_model_2.h5\n",
      "Epoch 82/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.5662 - acc: 0.3804 - val_loss: 1.5735 - val_acc: 0.3787\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.37853 to 0.37867, saving model to best_model_2.h5\n",
      "Epoch 83/150\n",
      "570000/570000 [==============================] - 34s 60us/step - loss: 1.5640 - acc: 0.3806 - val_loss: 1.5706 - val_acc: 0.3790\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.37867 to 0.37897, saving model to best_model_2.h5\n",
      "Epoch 84/150\n",
      "570000/570000 [==============================] - 31s 54us/step - loss: 1.5618 - acc: 0.3810 - val_loss: 1.5706 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.37897\n",
      "Epoch 85/150\n",
      "570000/570000 [==============================] - 35s 61us/step - loss: 1.5598 - acc: 0.3815 - val_loss: 1.5661 - val_acc: 0.3800\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.37897 to 0.37997, saving model to best_model_2.h5\n",
      "Epoch 86/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.5566 - acc: 0.3819 - val_loss: 1.5646 - val_acc: 0.3797\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.37997\n",
      "Epoch 87/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 1.5554 - acc: 0.3821 - val_loss: 1.5624 - val_acc: 0.3819\n",
      "\n",
      "Epoch 00087: val_acc improved from 0.37997 to 0.38193, saving model to best_model_2.h5\n",
      "Epoch 88/150\n",
      "570000/570000 [==============================] - 35s 61us/step - loss: 1.5529 - acc: 0.3828 - val_loss: 1.5599 - val_acc: 0.3801\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.38193\n",
      "Epoch 89/150\n",
      "570000/570000 [==============================] - 32s 56us/step - loss: 1.5504 - acc: 0.3833 - val_loss: 1.5587 - val_acc: 0.3767\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.38193\n",
      "Epoch 90/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.5481 - acc: 0.3837 - val_loss: 1.5566 - val_acc: 0.3787\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.38193\n",
      "Epoch 91/150\n",
      "570000/570000 [==============================] - 35s 61us/step - loss: 1.5458 - acc: 0.3841 - val_loss: 1.5541 - val_acc: 0.3813\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.38193\n",
      "Epoch 92/150\n",
      "570000/570000 [==============================] - 35s 61us/step - loss: 1.5435 - acc: 0.3849 - val_loss: 1.5517 - val_acc: 0.3809\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.38193\n",
      "Epoch 93/150\n",
      "570000/570000 [==============================] - 31s 55us/step - loss: 1.5417 - acc: 0.3853 - val_loss: 1.5506 - val_acc: 0.3815\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.38193\n",
      "Epoch 94/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.5401 - acc: 0.3858 - val_loss: 1.5479 - val_acc: 0.3819\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.38193\n",
      "Epoch 95/150\n",
      "570000/570000 [==============================] - 35s 62us/step - loss: 1.5377 - acc: 0.3863 - val_loss: 1.5462 - val_acc: 0.3826\n",
      "\n",
      "Epoch 00095: val_acc improved from 0.38193 to 0.38263, saving model to best_model_2.h5\n",
      "Epoch 96/150\n",
      "570000/570000 [==============================] - 30s 53us/step - loss: 1.5356 - acc: 0.3864 - val_loss: 1.5444 - val_acc: 0.3829\n",
      "\n",
      "Epoch 00096: val_acc improved from 0.38263 to 0.38287, saving model to best_model_2.h5\n",
      "Epoch 97/150\n",
      "570000/570000 [==============================] - 32s 56us/step - loss: 1.5339 - acc: 0.3866 - val_loss: 1.5451 - val_acc: 0.3842\n",
      "\n",
      "Epoch 00097: val_acc improved from 0.38287 to 0.38423, saving model to best_model_2.h5\n",
      "Epoch 98/150\n",
      "570000/570000 [==============================] - 32s 57us/step - loss: 1.5330 - acc: 0.3877 - val_loss: 1.5416 - val_acc: 0.3829\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.38423\n",
      "Epoch 99/150\n",
      "570000/570000 [==============================] - 30s 53us/step - loss: 1.5310 - acc: 0.3875 - val_loss: 1.5410 - val_acc: 0.3826\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.38423\n",
      "Epoch 100/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 1.5296 - acc: 0.3879 - val_loss: 1.5379 - val_acc: 0.3849\n",
      "\n",
      "Epoch 00100: val_acc improved from 0.38423 to 0.38490, saving model to best_model_2.h5\n",
      "Epoch 101/150\n",
      "570000/570000 [==============================] - 32s 57us/step - loss: 1.5275 - acc: 0.3886 - val_loss: 1.5404 - val_acc: 0.3846\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.38490\n",
      "Epoch 102/150\n",
      "570000/570000 [==============================] - 32s 57us/step - loss: 1.5266 - acc: 0.3895 - val_loss: 1.5348 - val_acc: 0.3843\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.38490\n",
      "Epoch 103/150\n",
      "570000/570000 [==============================] - 34s 60us/step - loss: 1.5246 - acc: 0.3899 - val_loss: 1.5332 - val_acc: 0.3868\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.38490 to 0.38677, saving model to best_model_2.h5\n",
      "Epoch 104/150\n",
      "570000/570000 [==============================] - 32s 57us/step - loss: 1.5231 - acc: 0.3906 - val_loss: 1.5338 - val_acc: 0.3857\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.38677\n",
      "Epoch 105/150\n",
      "570000/570000 [==============================] - 33s 59us/step - loss: 1.5216 - acc: 0.3911 - val_loss: 1.5310 - val_acc: 0.3849\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.38677\n",
      "Epoch 106/150\n",
      "570000/570000 [==============================] - 31s 54us/step - loss: 1.5201 - acc: 0.3914 - val_loss: 1.5306 - val_acc: 0.3874\n",
      "\n",
      "Epoch 00106: val_acc improved from 0.38677 to 0.38740, saving model to best_model_2.h5\n",
      "Epoch 107/150\n",
      "570000/570000 [==============================] - 34s 60us/step - loss: 1.5190 - acc: 0.3917 - val_loss: 1.5287 - val_acc: 0.3845\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.38740\n",
      "Epoch 108/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 1.5169 - acc: 0.3920 - val_loss: 1.5277 - val_acc: 0.3864\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.38740\n",
      "Epoch 109/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.5154 - acc: 0.3928 - val_loss: 1.5254 - val_acc: 0.3873\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.38740\n",
      "Epoch 110/150\n",
      "570000/570000 [==============================] - 34s 60us/step - loss: 1.5137 - acc: 0.3936 - val_loss: 1.5242 - val_acc: 0.3897\n",
      "\n",
      "Epoch 00110: val_acc improved from 0.38740 to 0.38967, saving model to best_model_2.h5\n",
      "Epoch 111/150\n",
      "570000/570000 [==============================] - 34s 60us/step - loss: 1.5126 - acc: 0.3941 - val_loss: 1.5229 - val_acc: 0.3884\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.38967\n",
      "Epoch 112/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.5110 - acc: 0.3943 - val_loss: 1.5218 - val_acc: 0.3907\n",
      "\n",
      "Epoch 00112: val_acc improved from 0.38967 to 0.39073, saving model to best_model_2.h5\n",
      "Epoch 113/150\n",
      "570000/570000 [==============================] - 35s 62us/step - loss: 1.5095 - acc: 0.3943 - val_loss: 1.5198 - val_acc: 0.3898\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.39073\n",
      "Epoch 114/150\n",
      "570000/570000 [==============================] - 35s 62us/step - loss: 1.5082 - acc: 0.3958 - val_loss: 1.5194 - val_acc: 0.3896\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.39073\n",
      "Epoch 115/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.5068 - acc: 0.3956 - val_loss: 1.5192 - val_acc: 0.3890\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.39073\n",
      "Epoch 116/150\n",
      "570000/570000 [==============================] - 31s 54us/step - loss: 1.5058 - acc: 0.3963 - val_loss: 1.5184 - val_acc: 0.3898\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.39073\n",
      "Epoch 117/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.5060 - acc: 0.3972 - val_loss: 1.5152 - val_acc: 0.3895\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.39073\n",
      "Epoch 118/150\n",
      "570000/570000 [==============================] - 30s 53us/step - loss: 1.5028 - acc: 0.3974 - val_loss: 1.5144 - val_acc: 0.3887\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.39073\n",
      "Epoch 119/150\n",
      "570000/570000 [==============================] - 32s 57us/step - loss: 1.5018 - acc: 0.3974 - val_loss: 1.5145 - val_acc: 0.3911\n",
      "\n",
      "Epoch 00119: val_acc improved from 0.39073 to 0.39110, saving model to best_model_2.h5\n",
      "Epoch 120/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 1.5010 - acc: 0.3987 - val_loss: 1.5120 - val_acc: 0.3914\n",
      "\n",
      "Epoch 00120: val_acc improved from 0.39110 to 0.39143, saving model to best_model_2.h5\n",
      "Epoch 121/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 1.4999 - acc: 0.3983 - val_loss: 1.5109 - val_acc: 0.3939\n",
      "\n",
      "Epoch 00121: val_acc improved from 0.39143 to 0.39387, saving model to best_model_2.h5\n",
      "Epoch 122/150\n",
      "570000/570000 [==============================] - 32s 56us/step - loss: 1.4979 - acc: 0.3994 - val_loss: 1.5108 - val_acc: 0.3951\n",
      "\n",
      "Epoch 00122: val_acc improved from 0.39387 to 0.39513, saving model to best_model_2.h5\n",
      "Epoch 123/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.4985 - acc: 0.4002 - val_loss: 1.5102 - val_acc: 0.3944\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.39513\n",
      "Epoch 124/150\n",
      "570000/570000 [==============================] - 35s 61us/step - loss: 1.4967 - acc: 0.4000 - val_loss: 1.5087 - val_acc: 0.3925\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.39513\n",
      "Epoch 125/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 1.4951 - acc: 0.4006 - val_loss: 1.5109 - val_acc: 0.3895\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.39513\n",
      "Epoch 126/150\n",
      "570000/570000 [==============================] - 34s 60us/step - loss: 1.4982 - acc: 0.4009 - val_loss: 1.5061 - val_acc: 0.3936\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.39513\n",
      "Epoch 127/150\n",
      "570000/570000 [==============================] - 35s 62us/step - loss: 1.4942 - acc: 0.4012 - val_loss: 1.5054 - val_acc: 0.3949\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.39513\n",
      "Epoch 128/150\n",
      "570000/570000 [==============================] - 35s 62us/step - loss: 1.4935 - acc: 0.4022 - val_loss: 1.5084 - val_acc: 0.3987\n",
      "\n",
      "Epoch 00128: val_acc improved from 0.39513 to 0.39867, saving model to best_model_2.h5\n",
      "Epoch 129/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.4927 - acc: 0.4024 - val_loss: 1.5044 - val_acc: 0.3919\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.39867\n",
      "Epoch 130/150\n",
      "570000/570000 [==============================] - 32s 55us/step - loss: 1.4906 - acc: 0.4026 - val_loss: 1.5031 - val_acc: 0.3940\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.39867\n",
      "Epoch 131/150\n",
      "570000/570000 [==============================] - 33s 59us/step - loss: 1.4902 - acc: 0.4035 - val_loss: 1.5032 - val_acc: 0.3963\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.39867\n",
      "Epoch 132/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 1.4888 - acc: 0.4040 - val_loss: 1.5004 - val_acc: 0.3959\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.39867\n",
      "Epoch 133/150\n",
      "570000/570000 [==============================] - 32s 56us/step - loss: 1.4863 - acc: 0.4042 - val_loss: 1.4993 - val_acc: 0.3988\n",
      "\n",
      "Epoch 00133: val_acc improved from 0.39867 to 0.39880, saving model to best_model_2.h5\n",
      "Epoch 134/150\n",
      "570000/570000 [==============================] - 30s 53us/step - loss: 1.4855 - acc: 0.4053 - val_loss: 1.4989 - val_acc: 0.3979\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.39880\n",
      "Epoch 135/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.4850 - acc: 0.4053 - val_loss: 1.4979 - val_acc: 0.3967\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.39880\n",
      "Epoch 136/150\n",
      "570000/570000 [==============================] - 31s 54us/step - loss: 1.4834 - acc: 0.4059 - val_loss: 1.4974 - val_acc: 0.3987\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.39880\n",
      "Epoch 137/150\n",
      "570000/570000 [==============================] - 35s 62us/step - loss: 1.4826 - acc: 0.4069 - val_loss: 1.4960 - val_acc: 0.3998\n",
      "\n",
      "Epoch 00137: val_acc improved from 0.39880 to 0.39980, saving model to best_model_2.h5\n",
      "Epoch 138/150\n",
      "570000/570000 [==============================] - 34s 59us/step - loss: 1.4814 - acc: 0.4070 - val_loss: 1.4957 - val_acc: 0.4025\n",
      "\n",
      "Epoch 00138: val_acc improved from 0.39980 to 0.40247, saving model to best_model_2.h5\n",
      "Epoch 139/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.4802 - acc: 0.4079 - val_loss: 1.4944 - val_acc: 0.4016\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.40247\n",
      "Epoch 140/150\n",
      "570000/570000 [==============================] - 31s 54us/step - loss: 1.4793 - acc: 0.4083 - val_loss: 1.4937 - val_acc: 0.4044\n",
      "\n",
      "Epoch 00140: val_acc improved from 0.40247 to 0.40440, saving model to best_model_2.h5\n",
      "Epoch 141/150\n",
      "570000/570000 [==============================] - 35s 62us/step - loss: 1.4789 - acc: 0.4091 - val_loss: 1.4925 - val_acc: 0.3999\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.40440\n",
      "Epoch 142/150\n",
      "570000/570000 [==============================] - 34s 60us/step - loss: 1.4784 - acc: 0.4090 - val_loss: 1.4937 - val_acc: 0.4011\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.40440\n",
      "Epoch 143/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.4777 - acc: 0.4100 - val_loss: 1.4912 - val_acc: 0.3986\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.40440\n",
      "Epoch 144/150\n",
      "570000/570000 [==============================] - 34s 60us/step - loss: 1.4767 - acc: 0.4097 - val_loss: 1.4909 - val_acc: 0.4059\n",
      "\n",
      "Epoch 00144: val_acc improved from 0.40440 to 0.40593, saving model to best_model_2.h5\n",
      "Epoch 145/150\n",
      "570000/570000 [==============================] - 35s 62us/step - loss: 1.4770 - acc: 0.4102 - val_loss: 1.4901 - val_acc: 0.4043\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.40593\n",
      "Epoch 146/150\n",
      "570000/570000 [==============================] - 33s 58us/step - loss: 1.4741 - acc: 0.4113 - val_loss: 1.4883 - val_acc: 0.4068\n",
      "\n",
      "Epoch 00146: val_acc improved from 0.40593 to 0.40677, saving model to best_model_2.h5\n",
      "Epoch 147/150\n",
      "570000/570000 [==============================] - 31s 55us/step - loss: 1.4728 - acc: 0.4125 - val_loss: 1.4876 - val_acc: 0.4011\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.40677\n",
      "Epoch 148/150\n",
      "570000/570000 [==============================] - 36s 63us/step - loss: 1.4718 - acc: 0.4125 - val_loss: 1.4866 - val_acc: 0.4037\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.40677\n",
      "Epoch 149/150\n",
      "570000/570000 [==============================] - 34s 60us/step - loss: 1.4729 - acc: 0.4122 - val_loss: 1.4863 - val_acc: 0.4066\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.40677\n",
      "Epoch 150/150\n",
      "570000/570000 [==============================] - 30s 53us/step - loss: 1.4709 - acc: 0.4132 - val_loss: 1.4861 - val_acc: 0.4029\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.40677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7eff54fb8748>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "mc = ModelCheckpoint('best_model_2.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "model.fit(trainX, trainY, epochs=150, batch_size=100000, validation_split=0.05, callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare layers size\n",
    "in_shape = (128,2,1)\n",
    "conv1_kernel_shape=(3,1)\n",
    "conv1_number_of_filters=64\n",
    "conv2_kernel_shape=(3,2)\n",
    "conv2_number_of_filters=16\n",
    "dense1_size = 128\n",
    "dense2_size = 10\n",
    "\n",
    "\n",
    "# Build model\n",
    "model_conv = Sequential()\n",
    "model_conv.add(Reshape((None,128,2,1), input_shape=in_shape))\n",
    "model_conv.add(Conv2D(conv1_number_of_filters, conv1_kernel_shape, strides=1,\n",
    "                 padding='same', data_format='channels_last',activation='relu'))\n",
    "model_conv.add(Conv2D(conv2_number_of_filters, conv2_kernel_shape, strides=1,\n",
    "                 padding='same', data_format='channels_last',activation='relu'))\n",
    "model_conv.add(Flatten())\n",
    "model_conv.add(Dense(dense1_size, activation='relu'))\n",
    "model_conv.add(Dense(dense2_size, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model_conv.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_conv.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
