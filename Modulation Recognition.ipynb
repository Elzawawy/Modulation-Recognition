{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "#Reset Button. Press when memory goes crazy fat !\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports cell\n",
    "import numpy as np\n",
    "import _pickle as cPickle\n",
    "import sys \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Deep Learning libs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start with data\n",
    "\n",
    "We use DeepSig Dataset: RadioML 2016.04C<br>\n",
    "A synthetic dataset, generated with GNU Radio, consisting of 11 modulations. This is a\n",
    "variable-SNR dataset with moderate LO drift, light fading, and numerous different\n",
    "labeled SNR increments for use in measuring performance across different signal and\n",
    "noise power scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "**The file is formatted as a \"pickle\" file which can be open for example in python by using cPickle.load(...)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"RML2016.10b.dat\"\n",
    "open_file = open(filename,'rb')\n",
    "data = cPickle.load(open_file, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use lists when accessing data from dict for ease of access.\n",
    "keys_list = list(data.keys())\n",
    "temp_list = []\n",
    "label_list = []\n",
    "snr_list = []\n",
    "for i in range(len(data.keys())):\n",
    "    curr_item = data[keys_list[i]] \n",
    "    temp_list.append(curr_item)\n",
    "    for j in range(curr_item.shape[0]):\n",
    "        label_list.append(keys_list[i][0])\n",
    "    #for j in rane(curr_item.shape[0]):\n",
    "    #    snr_list.append(keys_list[i][1])\n",
    "\n",
    "# Convert all lists into numpy arrays.\n",
    "X = np.array(temp_list).reshape(1200000,2,128)\n",
    "Y = np.array(label_list)\n",
    "\n",
    "# Clear All un-neccsarry lists created.\n",
    "temp_list.clear()\n",
    "label_list.clear()\n",
    "snr_list.clear()\n",
    "keys_list.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feature Spaces for data\n",
    "\n",
    "**Every sample is presented using two vectors each of them has 128 elements. Those two vectors are the in-phase and quadrature phase components of a sample.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data\n",
    "\n",
    "**Split the data into 50% for training/validation and 50% for testing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(X,Y, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Fully Connected Model\n",
    "<ul>\n",
    "\n",
    "1. The core data structure of Keras is a model. The simplest type of model is the Sequential model, a linear stack of layers.\n",
    "\n",
    "2. A 3-layer deep neural network consisiting only of fully connected layers of size 512, 256, 11 neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare layers size\n",
    "in_shape = (2,128)\n",
    "hidden1_size = 512\n",
    "hidden2_size = 256\n",
    "hidden3_size = 11\n",
    "\n",
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden1_size, input_shape = in_shape, activation = 'relu'))\n",
    "model.add(Dense(hidden2_size, activation = 'relu'))\n",
    "model.add(Dense(hidden3_size, activation = 'relu'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
