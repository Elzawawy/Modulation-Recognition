{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "spEHWc3bM4Yz",
    "outputId": "504c629f-2ec8-47c1-feca-8e5223de82fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "#Reset Button. Press when memory goes crazy fat !\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ooPNODuPM4ZE"
   },
   "outputs": [],
   "source": [
    "# imports cell\n",
    "import numpy as np\n",
    "import _pickle as cPickle\n",
    "import sys \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Deep Learning libs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten,Conv2D,Reshape\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEZByGdVM4ZU"
   },
   "source": [
    "# Let's start with data\n",
    "\n",
    "We use DeepSig Dataset: RadioML 2016.04C<br>\n",
    "A synthetic dataset, generated with GNU Radio, consisting of 11 modulations. This is a\n",
    "variable-SNR dataset with moderate LO drift, light fading, and numerous different\n",
    "labeled SNR increments for use in measuring performance across different signal and\n",
    "noise power scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y8ScyZz0M4ZW"
   },
   "source": [
    "## Loading data\n",
    "\n",
    "**The file is formatted as a \"pickle\" file which can be open for example in python by using cPickle.load(...)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "0bk118OHNG5T",
    "outputId": "e8dd92fc-d3be-4a05-b508-a03a27d76c6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "'My Drive'\n"
     ]
    }
   ],
   "source": [
    "#Loading the data from google drive \n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!ls \"/content/drive\"\n",
    "filename = \"/content/drive/My Drive/RML2016.10b.dat\"\n",
    "open_file = open(filename,'rb')\n",
    "data = cPickle.load(open_file, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d19_KvSfM4Zi"
   },
   "outputs": [],
   "source": [
    "# Use lists when accessing data from dict for ease of access.\n",
    "keys_list = list(data.keys())\n",
    "temp_list = []\n",
    "label_list = []\n",
    "snr_list = []\n",
    "for i in range(len(keys_list)):\n",
    "    curr_item = data[keys_list[i]] \n",
    "    temp_list.append(curr_item)\n",
    "    for j in range(curr_item.shape[0]):\n",
    "        label_list.append(keys_list[i][0])\n",
    "    #for j in rane(curr_item.shape[0]):\n",
    "    #    snr_list.append(keys_list[i][1])\n",
    "\n",
    "# Convert all lists into numpy arrays.\n",
    "X = np.array(temp_list).reshape(1200000,2,128)\n",
    "Y = np.array(label_list)\n",
    "\n",
    "# Clear All un-neccsarry lists created.\n",
    "temp_list.clear()\n",
    "label_list.clear()\n",
    "snr_list.clear()\n",
    "keys_list.clear()\n",
    "data.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZFC3tSbM4Zo"
   },
   "source": [
    "## Create feature Spaces for data\n",
    "\n",
    "**Every sample is presented using two vectors each of them has 128 elements. Those two vectors are the in-phase and quadrature phase components of a sample.**\n",
    "\n",
    "**In this notebook we only use the raw features data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mSiHv6GkM4Z4"
   },
   "source": [
    "## Splitting data\n",
    "\n",
    "**Split the data into 50% for training/validation and 50% for testing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYcsc3MPM4Z8"
   },
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(X,Y, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYCn66OAM4aF"
   },
   "source": [
    "## Encoding Labels\n",
    "\n",
    "Our class labels are currently represented as strings; however, Keras will assume that both:\n",
    "\n",
    "1. Labels are encoded as integers\n",
    "\n",
    "2. And furthermore, one-hot encoding is performed on these labels making each label represented as a vector rather than an integer\n",
    "\n",
    "To accomplish this encoding, we can use the LabelBinarizer  class from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i9JguIhUM4aJ"
   },
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "33I7X62QM4aV"
   },
   "source": [
    "# Defining the Fully Connected Model\n",
    "<ul>\n",
    "\n",
    "1. The core data structure of Keras is a model. The simplest type of model is the Sequential model, a linear stack of layers.\n",
    "\n",
    "2. A 3-layer deep neural network consisiting only of fully connected layers of size 512, 256, 11 neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "oNiGU1YBM4aY",
    "outputId": "30352113-8dcf-40d2-802c-87cd5e9dd19e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2, 512)            66048     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2, 256)            131328    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 202,506\n",
      "Trainable params: 202,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Declare layers size\n",
    "in_shape = (2,128)\n",
    "hidden1_size = 512\n",
    "hidden2_size = 256\n",
    "hidden3_size = 10\n",
    "\n",
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden1_size, input_shape = in_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(hidden2_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden3_size))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWuZ1aIxM4ah"
   },
   "source": [
    "## Fitting the model\n",
    "\n",
    "1. The training process will run for a fixed number of iterations (epochs) through the dataset.\n",
    "\n",
    "2. We can also set the number of instances that are evaluated before a weight update in the network is performed (batch size).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "ZvWTL53hM4aj",
    "outputId": "7a0874ac-0fdf-485b-92ed-b4ba83592957",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 570000 samples, validate on 30000 samples\n",
      "Epoch 1/150\n",
      "570000/570000 [==============================] - 4s 7us/step - loss: 0.9009 - acc: 0.6419 - val_loss: 1.5280 - val_acc: 0.4841\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.48407, saving model to best_fc_model_raw.h5\n",
      "Epoch 2/150\n",
      "570000/570000 [==============================] - 4s 7us/step - loss: 0.9001 - acc: 0.6422 - val_loss: 1.5405 - val_acc: 0.4846\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.48407 to 0.48460, saving model to best_fc_model_raw.h5\n",
      "Epoch 3/150\n",
      "570000/570000 [==============================] - 4s 7us/step - loss: 0.9013 - acc: 0.6422 - val_loss: 1.5340 - val_acc: 0.4822\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.48460\n",
      "Epoch 4/150\n",
      "570000/570000 [==============================] - 4s 7us/step - loss: 0.9003 - acc: 0.6420 - val_loss: 1.5358 - val_acc: 0.4833\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.48460\n",
      "Epoch 5/150\n",
      "570000/570000 [==============================] - 4s 7us/step - loss: 0.8991 - acc: 0.6424 - val_loss: 1.5493 - val_acc: 0.4826\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.48460\n",
      "Epoch 6/150\n",
      "570000/570000 [==============================] - 4s 7us/step - loss: 0.8989 - acc: 0.6422 - val_loss: 1.5350 - val_acc: 0.4847\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.48460 to 0.48470, saving model to best_fc_model_raw.h5\n",
      "Epoch 7/150\n",
      "570000/570000 [==============================] - 4s 7us/step - loss: 0.8990 - acc: 0.6430 - val_loss: 1.5362 - val_acc: 0.4825\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.48470\n",
      "Epoch 8/150\n",
      "570000/570000 [==============================] - 4s 7us/step - loss: 0.8984 - acc: 0.6430 - val_loss: 1.5313 - val_acc: 0.4840\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.48470\n",
      "Epoch 9/150\n",
      "570000/570000 [==============================] - 4s 7us/step - loss: 0.8971 - acc: 0.6436 - val_loss: 1.5353 - val_acc: 0.4827\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.48470\n",
      "Epoch 10/150\n",
      "570000/570000 [==============================] - 4s 7us/step - loss: 0.8973 - acc: 0.6433 - val_loss: 1.5390 - val_acc: 0.4853\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.48470 to 0.48527, saving model to best_fc_model_raw.h5\n",
      "Epoch 11/150\n",
      "570000/570000 [==============================] - 4s 7us/step - loss: 0.8974 - acc: 0.6436 - val_loss: 1.5485 - val_acc: 0.4839\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.48527\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f61f9795c88>"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "mc = ModelCheckpoint('best_fc_model_raw.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "model.fit(trainX, trainY, epochs=150, batch_size=750, validation_split=0.05,callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ewb-6WxLM3a-"
   },
   "source": [
    "# Defining the Convolutional Model\n",
    "<ul>\n",
    "    1.  Reshape the input to be the same as the first layer of the network's input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "_p26bEFKM4a8",
    "outputId": "ef92e2f3-2d31-4bf5-9b30-3faf26d2a690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_3 (Reshape)          (None, 128, 2, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 2, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 128, 2, 16)        6160      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 532,122\n",
      "Trainable params: 532,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Declare layers size\n",
    "in_shape = (2,128)\n",
    "conv1_kernel_shape=(3,1)\n",
    "conv1_number_of_filters=64\n",
    "conv2_kernel_shape=(3,2)\n",
    "conv2_number_of_filters=16\n",
    "dense1_size = 128\n",
    "dense2_size = 10\n",
    "\n",
    "\n",
    "# Build model\n",
    "model_conv = Sequential()\n",
    "model_conv.add(Reshape((128,2,1), input_shape=in_shape))\n",
    "model_conv.add(Conv2D(conv1_number_of_filters, conv1_kernel_shape, strides=1,\n",
    "                 padding='same', data_format='channels_last',activation='relu'))\n",
    "model_conv.add(Conv2D(conv2_number_of_filters, conv2_kernel_shape, strides=1,\n",
    "                 padding='same', data_format='channels_last',activation='relu'))\n",
    "model_conv.add(Flatten())\n",
    "model_conv.add(Dense(dense1_size, activation='relu'))\n",
    "model_conv.add(Dense(dense2_size, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model_conv.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "0Jj3VcGeb5ve",
    "outputId": "c4ce4711-ffc7-4384-ff44-fee1c82cb12e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 570000 samples, validate on 30000 samples\n",
      "Epoch 1/150\n",
      "570000/570000 [==============================] - 10s 17us/step - loss: 1.0043 - acc: 0.5954 - val_loss: 1.1378 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.53977, saving model to best_cnn_model_raw.h5\n",
      "Epoch 2/150\n",
      "570000/570000 [==============================] - 10s 17us/step - loss: 1.0049 - acc: 0.5952 - val_loss: 1.1386 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.53977 to 0.53983, saving model to best_cnn_model_raw.h5\n",
      "Epoch 3/150\n",
      "570000/570000 [==============================] - 10s 18us/step - loss: 1.0046 - acc: 0.5954 - val_loss: 1.1364 - val_acc: 0.5422\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.53983 to 0.54217, saving model to best_cnn_model_raw.h5\n",
      "Epoch 4/150\n",
      "570000/570000 [==============================] - 10s 18us/step - loss: 1.0037 - acc: 0.5957 - val_loss: 1.1372 - val_acc: 0.5415\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.54217\n",
      "Epoch 5/150\n",
      "570000/570000 [==============================] - 10s 18us/step - loss: 1.0036 - acc: 0.5957 - val_loss: 1.1394 - val_acc: 0.5406\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.54217\n",
      "Epoch 6/150\n",
      "570000/570000 [==============================] - 10s 18us/step - loss: 1.0043 - acc: 0.5951 - val_loss: 1.1390 - val_acc: 0.5407\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.54217\n",
      "Epoch 7/150\n",
      "570000/570000 [==============================] - 10s 18us/step - loss: 1.0042 - acc: 0.5957 - val_loss: 1.1382 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.54217\n",
      "Epoch 8/150\n",
      "570000/570000 [==============================] - 10s 18us/step - loss: 1.0028 - acc: 0.5961 - val_loss: 1.1385 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.54217\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f61f979a198>"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "mc = ModelCheckpoint('best_cnn_model_raw.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "model_conv.fit(trainX, trainY, epochs=150, batch_size=30000, validation_split=0.05,callbacks=[es,mc])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Modulation_Recognition_Raw_Features.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
