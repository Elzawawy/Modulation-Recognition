{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modulation_Recognition_Derivative_Features.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQbKoAw4O_Vc",
        "colab_type": "code",
        "outputId": "248b3b41-2486-4526-ddb0-a78fed0af11e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Reset Button. Press when memory goes crazy fat !\n",
        "%reset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo--pzZrPPCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports cell\n",
        "import numpy as np\n",
        "import _pickle as cPickle\n",
        "import sys \n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Deep Learning libs\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Flatten,Conv2D,Reshape\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI3p1-2EPj8z",
        "colab_type": "text"
      },
      "source": [
        "# Let's start with data\n",
        "\n",
        "We use DeepSig Dataset: RadioML 2016.04C<br>\n",
        "A synthetic dataset, generated with GNU Radio, consisting of 11 modulations. This is a\n",
        "variable-SNR dataset with moderate LO drift, light fading, and numerous different\n",
        "labeled SNR increments for use in measuring performance across different signal and\n",
        "noise power scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py2koxGAPqu1",
        "colab_type": "text"
      },
      "source": [
        "## Loading data\n",
        "\n",
        "**The file is formatted as a \"pickle\" file which can be open for example in python by using cPickle.load(...)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMJPzhpxHT2c",
        "colab_type": "text"
      },
      "source": [
        "#### Loading data in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZi3H4_FPYuf",
        "colab_type": "code",
        "outputId": "33f983c5-d60f-4aa0-a92d-106beec29c34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Loading the data from google drive \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive\"\n",
        "filename = \"/content/drive/My Drive/RML2016.10b.dat\"\n",
        "open_file = open(filename,'rb')\n",
        "data = cPickle.load(open_file, encoding='latin1')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "'My Drive'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsWWTvriHX-x",
        "colab_type": "text"
      },
      "source": [
        "#### Loading data locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sXc8x1iPvDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#(Using Jupyter not Colab, Run this cell or above not both)\n",
        "\n",
        "filename = \"RML2016.10b.dat\"\n",
        "open_file = open(filename,'rb')\n",
        "data = cPickle.load(open_file, encoding='latin1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLYKr_UyQFHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use lists when accessing data from dict for ease of access.\n",
        "keys_list = list(data.keys())\n",
        "temp_list = []\n",
        "label_list = []\n",
        "snr_list = []\n",
        "for i in range(len(keys_list)):\n",
        "    curr_item = data[keys_list[i]] \n",
        "    temp_list.append(curr_item)\n",
        "    for j in range(curr_item.shape[0]):\n",
        "        label_list.append(keys_list[i][0])\n",
        "    #for j in rane(curr_item.shape[0]):\n",
        "    #    snr_list.append(keys_list[i][1])\n",
        "\n",
        "# Convert all lists into numpy arrays.\n",
        "X = np.array(temp_list).reshape(1200000,2,128)\n",
        "Y = np.array(label_list)\n",
        "\n",
        "# Clear All un-neccsarry lists created.\n",
        "temp_list.clear()\n",
        "label_list.clear()\n",
        "snr_list.clear()\n",
        "keys_list.clear()\n",
        "data.clear()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcRWpUy-QLgO",
        "colab_type": "text"
      },
      "source": [
        "## Create feature Spaces for data\n",
        "\n",
        "**Every sample is presented using two vectors each of them has 128 elements. Those two vectors are the in-phase and quadrature phase components of a sample.**\n",
        "\n",
        "**In this notebook, we consider creating derivatve features and using them in our Neural Net, first alone then in a combination with raw features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jkstuX4QII6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combine_X = np.concatenate((np.apply_along_axis(lambda column:np.gradient(column),2,X),X),axis=1)\n",
        "X = np.apply_along_axis(lambda column:np.gradient(column),2,X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WrOlayiRAtN",
        "colab_type": "text"
      },
      "source": [
        "## Splitting data\n",
        "\n",
        "**Split the data into 50% for training/validation and 50% for testing.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5Sl3uf_QmHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(dtrainX, dtestX, dtrainY, dtestY) = train_test_split(X,Y, test_size=0.50, random_state=42)\n",
        "(ctrainX, ctestX, ctrainY, ctestY) = train_test_split(combine_X,Y, test_size=0.50, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXb0a4l2RJN5",
        "colab_type": "text"
      },
      "source": [
        "## Encoding Labels\n",
        "\n",
        "Our class labels are currently represented as strings; however, Keras will assume that both:\n",
        "\n",
        "1. Labels are encoded as integers\n",
        "\n",
        "2. And furthermore, one-hot encoding is performed on these labels making each label represented as a vector rather than an integer\n",
        "\n",
        "To accomplish this encoding, we can use the LabelBinarizer  class from scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee_Ixn6sQn2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lb = LabelBinarizer()\n",
        "dtrainY = lb.fit_transform(dtrainY)\n",
        "dtestY = lb.transform(dtestY)\n",
        "ctrainY = lb.fit_transform(ctrainY)\n",
        "ctestY = lb.transform(ctestY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlva4_f3ROwd",
        "colab_type": "text"
      },
      "source": [
        "# Defining the Fully Connected Model\n",
        "<ul>\n",
        "\n",
        "1. The core data structure of Keras is a model. The simplest type of model is the Sequential model, a linear stack of layers.\n",
        "\n",
        "2. A 3-layer deep neural network consisiting only of fully connected layers of size 512, 256, 11 neurons.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSxwioT6RMVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_fc_model(in_shape):\n",
        "  # Declare layers size\n",
        "  hidden1_size = 512\n",
        "  hidden2_size = 256\n",
        "  hidden3_size = 10\n",
        "\n",
        "  # Build model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(hidden1_size, input_shape = in_shape))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(hidden2_size))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(hidden3_size))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  # Compile model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOm4cYnlJcfC",
        "colab_type": "text"
      },
      "source": [
        "### Building the model with input shape. First we build a model for (2,128) input. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow383x2FJcAE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "8ff63d20-d7d6-46e4-f94e-c092af7944e3"
      },
      "source": [
        "model = build_fc_model((2,128))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 2, 512)            66048     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 2, 512)            0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2, 256)            131328    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 202,506\n",
            "Trainable params: 202,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnd4BvJoRamq",
        "colab_type": "text"
      },
      "source": [
        "## Fitting the model\n",
        "\n",
        "1. The training process will run for a fixed number of iterations (epochs) through the dataset.\n",
        "\n",
        "2. We can also set the number of instances that are evaluated before a weight update in the network is performed (batch size).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzQhAtSIRR4a",
        "colab_type": "code",
        "outputId": "0d552ef1-a3ae-4254-8fc3-1a7ee47e54fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1564
        }
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc = ModelCheckpoint('best_fc_model_der.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "model.fit(dtrainX, dtrainY, epochs=150, batch_size=30000, validation_split=0.05,callbacks=[es,mc])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 570000 samples, validate on 30000 samples\n",
            "Epoch 1/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.4016 - acc: 0.4257 - val_loss: 1.5031 - val_acc: 0.3889\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.38887, saving model to best_fc_model_der.h5\n",
            "Epoch 2/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.4010 - acc: 0.4256 - val_loss: 1.4987 - val_acc: 0.3889\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.38887 to 0.38893, saving model to best_fc_model_der.h5\n",
            "Epoch 3/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.4007 - acc: 0.4256 - val_loss: 1.5001 - val_acc: 0.3903\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.38893 to 0.39030, saving model to best_fc_model_der.h5\n",
            "Epoch 4/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.4007 - acc: 0.4264 - val_loss: 1.4994 - val_acc: 0.3894\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.39030\n",
            "Epoch 5/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.4008 - acc: 0.4263 - val_loss: 1.4991 - val_acc: 0.3901\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.39030\n",
            "Epoch 6/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.4014 - acc: 0.4257 - val_loss: 1.5006 - val_acc: 0.3909\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.39030 to 0.39090, saving model to best_fc_model_der.h5\n",
            "Epoch 7/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.3997 - acc: 0.4266 - val_loss: 1.5004 - val_acc: 0.3899\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.39090\n",
            "Epoch 8/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.4001 - acc: 0.4261 - val_loss: 1.4994 - val_acc: 0.3906\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.39090\n",
            "Epoch 9/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.3995 - acc: 0.4264 - val_loss: 1.4999 - val_acc: 0.3910\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.39090 to 0.39103, saving model to best_fc_model_der.h5\n",
            "Epoch 10/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.4013 - acc: 0.4258 - val_loss: 1.5062 - val_acc: 0.3894\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.39103\n",
            "Epoch 11/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.4025 - acc: 0.4254 - val_loss: 1.4987 - val_acc: 0.3898\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.39103\n",
            "Epoch 12/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.3995 - acc: 0.4265 - val_loss: 1.4985 - val_acc: 0.3919\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.39103 to 0.39193, saving model to best_fc_model_der.h5\n",
            "Epoch 13/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.3988 - acc: 0.4269 - val_loss: 1.4996 - val_acc: 0.3900\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.39193\n",
            "Epoch 14/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.3989 - acc: 0.4272 - val_loss: 1.5019 - val_acc: 0.3913\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.39193\n",
            "Epoch 15/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.4011 - acc: 0.4260 - val_loss: 1.4997 - val_acc: 0.3899\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.39193\n",
            "Epoch 16/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.3985 - acc: 0.4271 - val_loss: 1.4991 - val_acc: 0.3898\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.39193\n",
            "Epoch 17/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.3987 - acc: 0.4269 - val_loss: 1.5024 - val_acc: 0.3908\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.39193\n",
            "Epoch 18/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.3984 - acc: 0.4269 - val_loss: 1.4991 - val_acc: 0.3901\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.39193\n",
            "Epoch 19/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.3983 - acc: 0.4271 - val_loss: 1.4993 - val_acc: 0.3901\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.39193\n",
            "Epoch 20/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.3981 - acc: 0.4272 - val_loss: 1.4993 - val_acc: 0.3891\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.39193\n",
            "Epoch 21/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.3994 - acc: 0.4266 - val_loss: 1.5017 - val_acc: 0.3913\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.39193\n",
            "Epoch 22/150\n",
            "570000/570000 [==============================] - 1s 2us/step - loss: 1.3980 - acc: 0.4272 - val_loss: 1.4992 - val_acc: 0.3910\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.39193\n",
            "Epoch 00022: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb1ec196400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8d85XF1VriC",
        "colab_type": "text"
      },
      "source": [
        "### Building the Fully Connected Model for the first Combination (Raw Features + Derivative Features)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LafgW803RZMI",
        "colab_type": "code",
        "outputId": "2bf00da5-2d69-46c6-d66c-ae42a91d538b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model = build_fc_model((4,128))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 4, 512)            66048     \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 4, 512)            0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 4, 256)            131328    \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 4, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 10)                10250     \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 207,626\n",
            "Trainable params: 207,626\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng7lSFTOWcw7",
        "colab_type": "code",
        "outputId": "e947e8ca-7000-49fb-f9ff-5d3e7846a78b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4556
        }
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc = ModelCheckpoint('best_fc_model_comb1.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "model.fit(ctrainX, ctrainY, epochs=150, batch_size=1000, validation_split=0.05,callbacks=[es,mc])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 570000 samples, validate on 30000 samples\n",
            "Epoch 1/150\n",
            "570000/570000 [==============================] - 4s 8us/step - loss: 1.8237 - acc: 0.2887 - val_loss: 1.6516 - val_acc: 0.3476\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.34760, saving model to best_fc_model_comb1.h5\n",
            "Epoch 2/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.5888 - acc: 0.3689 - val_loss: 1.5529 - val_acc: 0.3755\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.34760 to 0.37553, saving model to best_fc_model_comb1.h5\n",
            "Epoch 3/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.5273 - acc: 0.3876 - val_loss: 1.5136 - val_acc: 0.3962\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.37553 to 0.39623, saving model to best_fc_model_comb1.h5\n",
            "Epoch 4/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.4981 - acc: 0.3981 - val_loss: 1.4939 - val_acc: 0.4006\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.39623 to 0.40060, saving model to best_fc_model_comb1.h5\n",
            "Epoch 5/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.4759 - acc: 0.4057 - val_loss: 1.4675 - val_acc: 0.4086\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.40060 to 0.40857, saving model to best_fc_model_comb1.h5\n",
            "Epoch 6/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.4545 - acc: 0.4152 - val_loss: 1.4514 - val_acc: 0.4217\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.40857 to 0.42170, saving model to best_fc_model_comb1.h5\n",
            "Epoch 7/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.4351 - acc: 0.4248 - val_loss: 1.4371 - val_acc: 0.4328\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.42170 to 0.43283, saving model to best_fc_model_comb1.h5\n",
            "Epoch 8/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.4164 - acc: 0.4344 - val_loss: 1.4282 - val_acc: 0.4432\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.43283 to 0.44320, saving model to best_fc_model_comb1.h5\n",
            "Epoch 9/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.4020 - acc: 0.4407 - val_loss: 1.4021 - val_acc: 0.4389\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.44320\n",
            "Epoch 10/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.3865 - acc: 0.4483 - val_loss: 1.3900 - val_acc: 0.4435\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.44320 to 0.44347, saving model to best_fc_model_comb1.h5\n",
            "Epoch 11/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.3735 - acc: 0.4525 - val_loss: 1.3881 - val_acc: 0.4429\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.44347\n",
            "Epoch 12/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.3602 - acc: 0.4575 - val_loss: 1.3755 - val_acc: 0.4464\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.44347 to 0.44637, saving model to best_fc_model_comb1.h5\n",
            "Epoch 13/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.3503 - acc: 0.4603 - val_loss: 1.3651 - val_acc: 0.4538\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.44637 to 0.45380, saving model to best_fc_model_comb1.h5\n",
            "Epoch 14/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.3393 - acc: 0.4649 - val_loss: 1.3584 - val_acc: 0.4529\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.45380\n",
            "Epoch 15/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.3309 - acc: 0.4671 - val_loss: 1.3530 - val_acc: 0.4565\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.45380 to 0.45650, saving model to best_fc_model_comb1.h5\n",
            "Epoch 16/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.3251 - acc: 0.4685 - val_loss: 1.3521 - val_acc: 0.4564\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.45650\n",
            "Epoch 17/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.3172 - acc: 0.4714 - val_loss: 1.3426 - val_acc: 0.4578\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.45650 to 0.45777, saving model to best_fc_model_comb1.h5\n",
            "Epoch 18/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.3107 - acc: 0.4739 - val_loss: 1.3496 - val_acc: 0.4559\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.45777\n",
            "Epoch 19/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.3054 - acc: 0.4758 - val_loss: 1.3327 - val_acc: 0.4575\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.45777\n",
            "Epoch 20/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.3005 - acc: 0.4777 - val_loss: 1.3282 - val_acc: 0.4660\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.45777 to 0.46603, saving model to best_fc_model_comb1.h5\n",
            "Epoch 21/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2957 - acc: 0.4788 - val_loss: 1.3262 - val_acc: 0.4628\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.46603\n",
            "Epoch 22/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2911 - acc: 0.4804 - val_loss: 1.3211 - val_acc: 0.4626\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.46603\n",
            "Epoch 23/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2856 - acc: 0.4820 - val_loss: 1.3292 - val_acc: 0.4628\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.46603\n",
            "Epoch 24/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2822 - acc: 0.4833 - val_loss: 1.3230 - val_acc: 0.4655\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.46603\n",
            "Epoch 25/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2781 - acc: 0.4851 - val_loss: 1.3256 - val_acc: 0.4631\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.46603\n",
            "Epoch 26/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.2743 - acc: 0.4866 - val_loss: 1.3168 - val_acc: 0.4676\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.46603 to 0.46757, saving model to best_fc_model_comb1.h5\n",
            "Epoch 27/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.2700 - acc: 0.4876 - val_loss: 1.3181 - val_acc: 0.4685\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.46757 to 0.46850, saving model to best_fc_model_comb1.h5\n",
            "Epoch 28/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2672 - acc: 0.4889 - val_loss: 1.3147 - val_acc: 0.4659\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.46850\n",
            "Epoch 29/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2628 - acc: 0.4902 - val_loss: 1.3094 - val_acc: 0.4672\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.46850\n",
            "Epoch 30/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2614 - acc: 0.4904 - val_loss: 1.3121 - val_acc: 0.4624\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.46850\n",
            "Epoch 31/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2562 - acc: 0.4929 - val_loss: 1.3169 - val_acc: 0.4657\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.46850\n",
            "Epoch 32/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2538 - acc: 0.4939 - val_loss: 1.3103 - val_acc: 0.4690\n",
            "\n",
            "Epoch 00032: val_acc improved from 0.46850 to 0.46900, saving model to best_fc_model_comb1.h5\n",
            "Epoch 33/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.2495 - acc: 0.4959 - val_loss: 1.3085 - val_acc: 0.4699\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.46900 to 0.46990, saving model to best_fc_model_comb1.h5\n",
            "Epoch 34/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2469 - acc: 0.4959 - val_loss: 1.3217 - val_acc: 0.4641\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.46990\n",
            "Epoch 35/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.2435 - acc: 0.4974 - val_loss: 1.3104 - val_acc: 0.4649\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.46990\n",
            "Epoch 36/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2407 - acc: 0.4982 - val_loss: 1.3039 - val_acc: 0.4676\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.46990\n",
            "Epoch 37/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2375 - acc: 0.4990 - val_loss: 1.3051 - val_acc: 0.4680\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.46990\n",
            "Epoch 38/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2346 - acc: 0.5004 - val_loss: 1.3119 - val_acc: 0.4685\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.46990\n",
            "Epoch 39/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.2314 - acc: 0.5021 - val_loss: 1.3027 - val_acc: 0.4684\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.46990\n",
            "Epoch 40/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.2284 - acc: 0.5029 - val_loss: 1.3070 - val_acc: 0.4690\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.46990\n",
            "Epoch 41/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2259 - acc: 0.5040 - val_loss: 1.3113 - val_acc: 0.4637\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.46990\n",
            "Epoch 42/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2222 - acc: 0.5050 - val_loss: 1.3009 - val_acc: 0.4697\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.46990\n",
            "Epoch 43/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.2220 - acc: 0.5060 - val_loss: 1.2955 - val_acc: 0.4730\n",
            "\n",
            "Epoch 00043: val_acc improved from 0.46990 to 0.47303, saving model to best_fc_model_comb1.h5\n",
            "Epoch 44/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2159 - acc: 0.5075 - val_loss: 1.2944 - val_acc: 0.4718\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.47303\n",
            "Epoch 45/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2155 - acc: 0.5076 - val_loss: 1.2978 - val_acc: 0.4711\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.47303\n",
            "Epoch 46/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2134 - acc: 0.5090 - val_loss: 1.2941 - val_acc: 0.4728\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.47303\n",
            "Epoch 47/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2071 - acc: 0.5104 - val_loss: 1.2979 - val_acc: 0.4732\n",
            "\n",
            "Epoch 00047: val_acc improved from 0.47303 to 0.47323, saving model to best_fc_model_comb1.h5\n",
            "Epoch 48/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2063 - acc: 0.5120 - val_loss: 1.2964 - val_acc: 0.4706\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.47323\n",
            "Epoch 49/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.2040 - acc: 0.5129 - val_loss: 1.2906 - val_acc: 0.4745\n",
            "\n",
            "Epoch 00049: val_acc improved from 0.47323 to 0.47450, saving model to best_fc_model_comb1.h5\n",
            "Epoch 50/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.1997 - acc: 0.5141 - val_loss: 1.2923 - val_acc: 0.4749\n",
            "\n",
            "Epoch 00050: val_acc improved from 0.47450 to 0.47490, saving model to best_fc_model_comb1.h5\n",
            "Epoch 51/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.1992 - acc: 0.5143 - val_loss: 1.2942 - val_acc: 0.4742\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.47490\n",
            "Epoch 52/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.1950 - acc: 0.5159 - val_loss: 1.2904 - val_acc: 0.4718\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.47490\n",
            "Epoch 53/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.1947 - acc: 0.5164 - val_loss: 1.2915 - val_acc: 0.4770\n",
            "\n",
            "Epoch 00053: val_acc improved from 0.47490 to 0.47700, saving model to best_fc_model_comb1.h5\n",
            "Epoch 54/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.1908 - acc: 0.5180 - val_loss: 1.2953 - val_acc: 0.4728\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.47700\n",
            "Epoch 55/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.1892 - acc: 0.5193 - val_loss: 1.2959 - val_acc: 0.4742\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.47700\n",
            "Epoch 56/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.1859 - acc: 0.5205 - val_loss: 1.2846 - val_acc: 0.4779\n",
            "\n",
            "Epoch 00056: val_acc improved from 0.47700 to 0.47787, saving model to best_fc_model_comb1.h5\n",
            "Epoch 57/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.1846 - acc: 0.5212 - val_loss: 1.2916 - val_acc: 0.4782\n",
            "\n",
            "Epoch 00057: val_acc improved from 0.47787 to 0.47820, saving model to best_fc_model_comb1.h5\n",
            "Epoch 58/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.1810 - acc: 0.5222 - val_loss: 1.2929 - val_acc: 0.4714\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.47820\n",
            "Epoch 59/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.1791 - acc: 0.5237 - val_loss: 1.2852 - val_acc: 0.4784\n",
            "\n",
            "Epoch 00059: val_acc improved from 0.47820 to 0.47837, saving model to best_fc_model_comb1.h5\n",
            "Epoch 60/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.1760 - acc: 0.5237 - val_loss: 1.2847 - val_acc: 0.4778\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.47837\n",
            "Epoch 61/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.1750 - acc: 0.5252 - val_loss: 1.2852 - val_acc: 0.4762\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.47837\n",
            "Epoch 62/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.1736 - acc: 0.5253 - val_loss: 1.3017 - val_acc: 0.4705\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.47837\n",
            "Epoch 63/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.1712 - acc: 0.5265 - val_loss: 1.3061 - val_acc: 0.4700\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.47837\n",
            "Epoch 64/150\n",
            "570000/570000 [==============================] - 4s 6us/step - loss: 1.1686 - acc: 0.5274 - val_loss: 1.2959 - val_acc: 0.4743\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.47837\n",
            "Epoch 65/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.1667 - acc: 0.5292 - val_loss: 1.2858 - val_acc: 0.4762\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.47837\n",
            "Epoch 66/150\n",
            "570000/570000 [==============================] - 4s 7us/step - loss: 1.1638 - acc: 0.5298 - val_loss: 1.2915 - val_acc: 0.4776\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.47837\n",
            "Epoch 00066: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb17fd9a048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdxlNUtPZzsX",
        "colab_type": "text"
      },
      "source": [
        "# Defining the Convolutional Model\n",
        "<ul>\n",
        "    1.  Reshape the input to be the same as the first layer of the network's input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKM6zqQTXvQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_cnn_model(in_shape):\n",
        "  # Declare layers size\n",
        "  conv1_kernel_shape=(3,1)\n",
        "  conv1_number_of_filters=64\n",
        "  conv2_kernel_shape=(3,2)\n",
        "  conv2_number_of_filters=16\n",
        "  dense1_size = 128\n",
        "  dense2_size = 10\n",
        "\n",
        "\n",
        "  # Build model\n",
        "  model_conv = Sequential()\n",
        "  model_conv.add(Reshape((128,in_shape[0],1), input_shape=in_shape))\n",
        "  model_conv.add(Conv2D(conv1_number_of_filters, conv1_kernel_shape, strides=1,\n",
        "                   padding='same', data_format='channels_last',activation='relu'))\n",
        "  model_conv.add(Conv2D(conv2_number_of_filters, conv2_kernel_shape, strides=1,\n",
        "                   padding='same', data_format='channels_last',activation='relu'))\n",
        "  model_conv.add(Flatten())\n",
        "  model_conv.add(Dense(dense1_size, activation='relu'))\n",
        "  model_conv.add(Dense(dense2_size, activation='softmax'))\n",
        "\n",
        "  # Compile model\n",
        "  model_conv.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  model_conv.summary()\n",
        "  return model_conv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKIJB7XGSaS_",
        "colab_type": "text"
      },
      "source": [
        "### Building the model with input shape. First we build a model for (2,128) input. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QnNbd_TShSX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "b0700b2f-bd27-4f53-824c-57e7abc35491"
      },
      "source": [
        "model = build_cnn_model((2,128))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_5 (Reshape)          (None, 128, 2, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 128, 2, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 128, 2, 16)        6160      \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 128)               524416    \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 532,122\n",
            "Trainable params: 532,122\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL6uS8V6aJ_b",
        "colab_type": "code",
        "outputId": "8ca375a3-a702-48b8-b8ab-afc95f6e60d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1275
        }
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc = ModelCheckpoint('best_cnn_model_der.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "model.fit(dtrainX, dtrainY, epochs=150, batch_size=1000, validation_split=0.05,callbacks=[es,mc])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 570000 samples, validate on 30000 samples\n",
            "Epoch 1/150\n",
            "570000/570000 [==============================] - 13s 23us/step - loss: 2.3026 - acc: 0.0996 - val_loss: 2.3025 - val_acc: 0.1038\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.10383, saving model to best_cnn_model_der.h5\n",
            "Epoch 2/150\n",
            "570000/570000 [==============================] - 10s 18us/step - loss: 2.3021 - acc: 0.1060 - val_loss: 2.3013 - val_acc: 0.1184\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.10383 to 0.11837, saving model to best_cnn_model_der.h5\n",
            "Epoch 3/150\n",
            "570000/570000 [==============================] - 10s 18us/step - loss: 2.2995 - acc: 0.1152 - val_loss: 2.2973 - val_acc: 0.1196\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.11837 to 0.11957, saving model to best_cnn_model_der.h5\n",
            "Epoch 4/150\n",
            "570000/570000 [==============================] - 10s 18us/step - loss: 2.2946 - acc: 0.1197 - val_loss: 2.2929 - val_acc: 0.1185\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.11957\n",
            "Epoch 5/150\n",
            "570000/570000 [==============================] - 10s 18us/step - loss: 2.2919 - acc: 0.1195 - val_loss: 2.2922 - val_acc: 0.1216\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.11957 to 0.12157, saving model to best_cnn_model_der.h5\n",
            "Epoch 6/150\n",
            "570000/570000 [==============================] - 10s 18us/step - loss: 2.2917 - acc: 0.1204 - val_loss: 2.2918 - val_acc: 0.1215\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.12157\n",
            "Epoch 7/150\n",
            "570000/570000 [==============================] - 10s 17us/step - loss: 2.2912 - acc: 0.1208 - val_loss: 2.2917 - val_acc: 0.1204\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.12157\n",
            "Epoch 8/150\n",
            "570000/570000 [==============================] - 10s 17us/step - loss: 2.2910 - acc: 0.1204 - val_loss: 2.2914 - val_acc: 0.1208\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.12157\n",
            "Epoch 9/150\n",
            "570000/570000 [==============================] - 10s 18us/step - loss: 2.2908 - acc: 0.1205 - val_loss: 2.2913 - val_acc: 0.1201\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.12157\n",
            "Epoch 10/150\n",
            "570000/570000 [==============================] - 10s 18us/step - loss: 2.2911 - acc: 0.1208 - val_loss: 2.2920 - val_acc: 0.1200\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.12157\n",
            "Epoch 11/150\n",
            "570000/570000 [==============================] - 10s 18us/step - loss: 2.2913 - acc: 0.1213 - val_loss: 2.2919 - val_acc: 0.1205\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.12157\n",
            "Epoch 12/150\n",
            "570000/570000 [==============================] - 10s 18us/step - loss: 2.2908 - acc: 0.1209 - val_loss: 2.2914 - val_acc: 0.1198\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.12157\n",
            "Epoch 13/150\n",
            "570000/570000 [==============================] - 10s 18us/step - loss: 2.2907 - acc: 0.1214 - val_loss: 2.2912 - val_acc: 0.1203\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.12157\n",
            "Epoch 14/150\n",
            "480000/570000 [========================>.....] - ETA: 1s - loss: 2.2904 - acc: 0.1213"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-859b4722b558>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_cnn_model_der.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcaArtsgfH6c",
        "colab_type": "text"
      },
      "source": [
        "### Defining the CNN Model on the combined data of raw features and derivative features (Same but different input shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nYq99_-bJmR",
        "colab_type": "code",
        "outputId": "a72907fe-76a5-4ed7-c79b-789a91aad02c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "model = build_cnn_model((4,128))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_7 (Reshape)          (None, 128, 4, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 128, 4, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 128, 4, 16)        6160      \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 128)               1048704   \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,056,410\n",
            "Trainable params: 1,056,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6Z20JiDfZbt",
        "colab_type": "code",
        "outputId": "277f6e21-60ad-426a-db52-52f188e6f6a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6103
        }
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc = ModelCheckpoint('best_cnn_model_comb1.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "model.fit(ctrainX, ctrainY, epochs=150, batch_size=1000, validation_split=0.05,callbacks=[mc])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 570000 samples, validate on 30000 samples\n",
            "Epoch 1/150\n",
            "570000/570000 [==============================] - 21s 37us/step - loss: 1.8366 - acc: 0.2797 - val_loss: 1.5759 - val_acc: 0.3644\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.36440, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 2/150\n",
            "570000/570000 [==============================] - 20s 36us/step - loss: 1.4605 - acc: 0.4155 - val_loss: 1.3872 - val_acc: 0.4363\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.36440 to 0.43627, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 3/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.3645 - acc: 0.4499 - val_loss: 1.3464 - val_acc: 0.4517\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.43627 to 0.45167, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 4/150\n",
            "570000/570000 [==============================] - 20s 34us/step - loss: 1.3249 - acc: 0.4639 - val_loss: 1.3252 - val_acc: 0.4655\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.45167 to 0.46550, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 5/150\n",
            "570000/570000 [==============================] - 20s 34us/step - loss: 1.2965 - acc: 0.4740 - val_loss: 1.2985 - val_acc: 0.4545\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.46550\n",
            "Epoch 6/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.2709 - acc: 0.4827 - val_loss: 1.2727 - val_acc: 0.4789\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.46550 to 0.47887, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 7/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.2511 - acc: 0.4897 - val_loss: 1.2644 - val_acc: 0.4822\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.47887 to 0.48220, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 8/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.2369 - acc: 0.4939 - val_loss: 1.2447 - val_acc: 0.4912\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.48220 to 0.49120, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 9/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.2224 - acc: 0.5000 - val_loss: 1.2442 - val_acc: 0.4779\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.49120\n",
            "Epoch 10/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.2083 - acc: 0.5052 - val_loss: 1.2287 - val_acc: 0.4968\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.49120 to 0.49677, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 11/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.1999 - acc: 0.5083 - val_loss: 1.2218 - val_acc: 0.4841\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.49677\n",
            "Epoch 12/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.1865 - acc: 0.5138 - val_loss: 1.2050 - val_acc: 0.5024\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.49677 to 0.50237, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 13/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.1789 - acc: 0.5165 - val_loss: 1.2046 - val_acc: 0.5033\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.50237 to 0.50330, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 14/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.1698 - acc: 0.5200 - val_loss: 1.2111 - val_acc: 0.4962\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.50330\n",
            "Epoch 15/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.1618 - acc: 0.5247 - val_loss: 1.1903 - val_acc: 0.5035\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.50330 to 0.50350, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 16/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.1505 - acc: 0.5292 - val_loss: 1.1828 - val_acc: 0.5074\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.50350 to 0.50737, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 17/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.1471 - acc: 0.5312 - val_loss: 1.1958 - val_acc: 0.5062\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.50737\n",
            "Epoch 18/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.1410 - acc: 0.5332 - val_loss: 1.1837 - val_acc: 0.5091\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.50737 to 0.50910, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 19/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.1368 - acc: 0.5354 - val_loss: 1.1931 - val_acc: 0.5043\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.50910\n",
            "Epoch 20/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.1312 - acc: 0.5381 - val_loss: 1.1810 - val_acc: 0.5130\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.50910 to 0.51297, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 21/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.1258 - acc: 0.5397 - val_loss: 1.1838 - val_acc: 0.5129\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.51297\n",
            "Epoch 22/150\n",
            "570000/570000 [==============================] - 20s 34us/step - loss: 1.1212 - acc: 0.5424 - val_loss: 1.1823 - val_acc: 0.5117\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.51297\n",
            "Epoch 23/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.1170 - acc: 0.5439 - val_loss: 1.1764 - val_acc: 0.5156\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.51297 to 0.51560, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 24/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.1117 - acc: 0.5462 - val_loss: 1.1770 - val_acc: 0.5150\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.51560\n",
            "Epoch 25/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.1081 - acc: 0.5473 - val_loss: 1.1752 - val_acc: 0.5128\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.51560\n",
            "Epoch 26/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.1053 - acc: 0.5491 - val_loss: 1.1754 - val_acc: 0.5133\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.51560\n",
            "Epoch 27/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.1023 - acc: 0.5502 - val_loss: 1.1763 - val_acc: 0.5148\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.51560\n",
            "Epoch 28/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0963 - acc: 0.5522 - val_loss: 1.1743 - val_acc: 0.5182\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.51560 to 0.51823, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 29/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0924 - acc: 0.5544 - val_loss: 1.1863 - val_acc: 0.5097\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.51823\n",
            "Epoch 30/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0893 - acc: 0.5559 - val_loss: 1.1897 - val_acc: 0.5122\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.51823\n",
            "Epoch 31/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0861 - acc: 0.5571 - val_loss: 1.1780 - val_acc: 0.5160\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.51823\n",
            "Epoch 32/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0812 - acc: 0.5593 - val_loss: 1.1781 - val_acc: 0.5212\n",
            "\n",
            "Epoch 00032: val_acc improved from 0.51823 to 0.52123, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 33/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0774 - acc: 0.5609 - val_loss: 1.1765 - val_acc: 0.5186\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.52123\n",
            "Epoch 34/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0752 - acc: 0.5622 - val_loss: 1.1826 - val_acc: 0.5172\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.52123\n",
            "Epoch 35/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0727 - acc: 0.5631 - val_loss: 1.1893 - val_acc: 0.5144\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.52123\n",
            "Epoch 36/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0692 - acc: 0.5646 - val_loss: 1.1960 - val_acc: 0.5139\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.52123\n",
            "Epoch 37/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0661 - acc: 0.5665 - val_loss: 1.1939 - val_acc: 0.5174\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.52123\n",
            "Epoch 38/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0620 - acc: 0.5682 - val_loss: 1.2147 - val_acc: 0.5090\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.52123\n",
            "Epoch 39/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0568 - acc: 0.5704 - val_loss: 1.1876 - val_acc: 0.5142\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.52123\n",
            "Epoch 40/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0553 - acc: 0.5704 - val_loss: 1.1949 - val_acc: 0.5194\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.52123\n",
            "Epoch 41/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0525 - acc: 0.5720 - val_loss: 1.1906 - val_acc: 0.5182\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.52123\n",
            "Epoch 42/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0499 - acc: 0.5731 - val_loss: 1.1986 - val_acc: 0.5167\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.52123\n",
            "Epoch 43/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0438 - acc: 0.5762 - val_loss: 1.2032 - val_acc: 0.5095\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.52123\n",
            "Epoch 44/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0413 - acc: 0.5770 - val_loss: 1.1984 - val_acc: 0.5204\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.52123\n",
            "Epoch 45/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0418 - acc: 0.5771 - val_loss: 1.1959 - val_acc: 0.5162\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.52123\n",
            "Epoch 46/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0355 - acc: 0.5791 - val_loss: 1.2045 - val_acc: 0.5150\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.52123\n",
            "Epoch 47/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0361 - acc: 0.5792 - val_loss: 1.2019 - val_acc: 0.5194\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.52123\n",
            "Epoch 48/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0309 - acc: 0.5815 - val_loss: 1.2031 - val_acc: 0.5150\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.52123\n",
            "Epoch 49/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0276 - acc: 0.5829 - val_loss: 1.2111 - val_acc: 0.5151\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.52123\n",
            "Epoch 50/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0243 - acc: 0.5842 - val_loss: 1.2180 - val_acc: 0.5172\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.52123\n",
            "Epoch 51/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0209 - acc: 0.5854 - val_loss: 1.2093 - val_acc: 0.5152\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.52123\n",
            "Epoch 52/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0212 - acc: 0.5851 - val_loss: 1.2140 - val_acc: 0.5147\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.52123\n",
            "Epoch 53/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0162 - acc: 0.5878 - val_loss: 1.2471 - val_acc: 0.5063\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.52123\n",
            "Epoch 54/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0169 - acc: 0.5876 - val_loss: 1.2198 - val_acc: 0.5117\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.52123\n",
            "Epoch 55/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0103 - acc: 0.5906 - val_loss: 1.2125 - val_acc: 0.5183\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.52123\n",
            "Epoch 56/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0087 - acc: 0.5906 - val_loss: 1.2145 - val_acc: 0.5204\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.52123\n",
            "Epoch 57/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0067 - acc: 0.5923 - val_loss: 1.2215 - val_acc: 0.5203\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.52123\n",
            "Epoch 58/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0014 - acc: 0.5937 - val_loss: 1.2293 - val_acc: 0.5188\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.52123\n",
            "Epoch 59/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 1.0013 - acc: 0.5936 - val_loss: 1.2445 - val_acc: 0.5109\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.52123\n",
            "Epoch 60/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9984 - acc: 0.5946 - val_loss: 1.2321 - val_acc: 0.5204\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.52123\n",
            "Epoch 61/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9953 - acc: 0.5964 - val_loss: 1.2261 - val_acc: 0.5204\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.52123\n",
            "Epoch 62/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9906 - acc: 0.5985 - val_loss: 1.2329 - val_acc: 0.5192\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.52123\n",
            "Epoch 63/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9885 - acc: 0.5990 - val_loss: 1.2454 - val_acc: 0.5116\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.52123\n",
            "Epoch 64/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9862 - acc: 0.6001 - val_loss: 1.2397 - val_acc: 0.5120\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.52123\n",
            "Epoch 65/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9849 - acc: 0.6007 - val_loss: 1.2401 - val_acc: 0.5219\n",
            "\n",
            "Epoch 00065: val_acc improved from 0.52123 to 0.52190, saving model to best_cnn_model_comb1.h5\n",
            "Epoch 66/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9808 - acc: 0.6019 - val_loss: 1.2459 - val_acc: 0.5194\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.52190\n",
            "Epoch 67/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9789 - acc: 0.6032 - val_loss: 1.2493 - val_acc: 0.5193\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.52190\n",
            "Epoch 68/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9767 - acc: 0.6039 - val_loss: 1.2556 - val_acc: 0.5186\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.52190\n",
            "Epoch 69/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9720 - acc: 0.6056 - val_loss: 1.2730 - val_acc: 0.5152\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.52190\n",
            "Epoch 70/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9721 - acc: 0.6058 - val_loss: 1.2618 - val_acc: 0.5184\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.52190\n",
            "Epoch 71/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9698 - acc: 0.6066 - val_loss: 1.2733 - val_acc: 0.5173\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.52190\n",
            "Epoch 72/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9648 - acc: 0.6082 - val_loss: 1.2656 - val_acc: 0.5177\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.52190\n",
            "Epoch 73/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9625 - acc: 0.6097 - val_loss: 1.2658 - val_acc: 0.5163\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.52190\n",
            "Epoch 74/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9617 - acc: 0.6098 - val_loss: 1.2741 - val_acc: 0.5179\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.52190\n",
            "Epoch 75/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9593 - acc: 0.6107 - val_loss: 1.2783 - val_acc: 0.5185\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.52190\n",
            "Epoch 76/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9547 - acc: 0.6121 - val_loss: 1.2783 - val_acc: 0.5120\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.52190\n",
            "Epoch 77/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9509 - acc: 0.6138 - val_loss: 1.2837 - val_acc: 0.5167\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.52190\n",
            "Epoch 78/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9503 - acc: 0.6148 - val_loss: 1.3018 - val_acc: 0.5161\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.52190\n",
            "Epoch 79/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9462 - acc: 0.6166 - val_loss: 1.3134 - val_acc: 0.5095\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.52190\n",
            "Epoch 80/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9460 - acc: 0.6162 - val_loss: 1.3135 - val_acc: 0.5114\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.52190\n",
            "Epoch 81/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9418 - acc: 0.6175 - val_loss: 1.2904 - val_acc: 0.5190\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.52190\n",
            "Epoch 82/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9414 - acc: 0.6179 - val_loss: 1.3105 - val_acc: 0.5122\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.52190\n",
            "Epoch 83/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9397 - acc: 0.6187 - val_loss: 1.2934 - val_acc: 0.5178\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.52190\n",
            "Epoch 84/150\n",
            "570000/570000 [==============================] - 20s 35us/step - loss: 0.9360 - acc: 0.6204 - val_loss: 1.3054 - val_acc: 0.5186\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.52190\n",
            "Epoch 85/150\n",
            "531000/570000 [==========================>...] - ETA: 1s - loss: 0.9322 - acc: 0.6215"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-69d865d951d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_cnn_model_comb1.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    185\u001b[0m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[1;32m    186\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}